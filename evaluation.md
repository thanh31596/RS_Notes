| Metric                                                  | Primary Objective                                                           | Best‑fit Scenarios (examples)                                                                     | Rank Sensitivity                                          | Key Limitations                                                                  |
| ------------------------------------------------------- | --------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------- | --------------------------------------------------------- | -------------------------------------------------------------------------------- |
| **MRR** (Mean Reciprocal Rank)                          | Maximise probability that the *first* relevant item appears early           | Single‑choice interfaces: voice assistants, FAQ auto‑completion, one‑shot “next question” hints   | **High** – only the first relevant item counts (1 ⁄ rank) | Ignores additional relevant items; unstable when many users have zero positives  |
| **NDCG** (Normalized Discounted Cumulative Gain)        | Reward placing higher‑graded items earlier while considering the whole list | Streaming media, e‑commerce where ratings or dwell‑time are graded; multi‑level implicit feedback | **High** – logarithmic discount across positions          | Reduces to Hit Rate when relevance is binary; more costly to compute             |
| **Hit Rate** (a.k.a. Success / Recall‑at‑k, single‑hit) | Ensure at least one known positive appears in the top k                     | Extremely sparse implicit‑feedback data; recall “safety net” in production A/B tests              | **None** (position within top k ignored)                  | Cannot distinguish position 1 vs position k; insensitive to ranking quality      |
| **Precision @ k**                                       | Maximise purity of the recommendation list                                  | Limited‑slot UIs: home‑page hero slots, push notifications, email subject‑line suggestions        | **Position‑independent** within k                         | Penalises recall in long‑tail domains; may mislead when very few positives exist |
| **Recall @ k**                                          | Cover as many relevant items as possible                                    | Catalogue browsing, playlist continuation, “people you may know,” fraud detection                 | **Position‑independent** within k                         | Can be low even for good models when item space is huge; ignores false positives |
| **F1‑Score** (harmonic mean of Precision & Recall)      | Balance Precision and Recall with equal weight                              | Binary “send / don’t send” decisions; single‑item recommend / alert systems                       | Inherits properties of Precision & Recall                 | Assumes equal cost of false + / false –; less interpretable for ranked lists     |

**How to read the table**

* Choose **MRR** when the interface shows exactly one suggestion and speed to the first hit dominates.
* Choose **NDCG** when relevance is graded and ordering quality drives engagement.
* Monitor **Hit Rate** alongside a rank‑sensitive metric to guard against recall regressions.
* Optimise **Precision** if every wrong item is a conspicuous error; **Recall** if omissions hurt more than noise.
* Use **F1** only when you genuinely need a single scalar for a binary‑choice task.
